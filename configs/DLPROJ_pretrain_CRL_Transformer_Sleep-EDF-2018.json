{
    "_comment": "Pretraining Encoder backbone using Contrastive Learning. Run train_crl_dlproj.py script with this config. Also train classifier, benchmark it and generate embeddings",

    "dataset": {
        "name": "Sleep-EDF-2018",
        "eeg_channel": "Fpz-Cz",
        "num_splits": 10,
        "seq_len": 1,
        "target_idx": 0,
        "root_dir": "./",
        "masking": false
    },

    "backbone": {
        "name": "Transformer",
        "fs": 100,
        "second": 30,
        "time_window": 5,
        "time_step": 0.5,
        "encoder_embed_dim": 128,
        "encoder_heads": 8,
        "encoder_depths": 6,
        "decoder_embed_dim": 128,
        "decoder_heads": 4,
        "decoder_depths": 8,
        "projection_hidden": [1024, 512],
        "use_sig_backbone": false,
        "input_size": 3000,
        "num_patches": 1,
        "use_cls": false
    },

    "classifier": {
        "_comment": "Classifier used to finetune it and benchmark -> linear Evaluation",
        "name": "DLProjMLP",
        "input_dim": 128,
        "hidden_dim": 256,
        "dropout": 0.5,
        "num_classes": 5
    },

    "training_params": {
        "mode": "pretrain",
        "loss": "NTXent",
        "max_epochs": 500,
        "batch_size": 128,
        "lr": 0.0005,
        "weight_decay": 0.0001,
        "temperature": 0.07,
        "val_period": 649,
        "early_stopping": {
            "mode": "min",
            "patience": 4,
            "_comment": "as validation is done at half an epoch, we max wait 4 validations(=2epochs)"
        },
        "classifier_epochs": 100
    }
}
